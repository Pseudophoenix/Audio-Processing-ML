{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6cd712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2c53ab",
   "metadata": {},
   "source": [
    "### Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007dffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile as wav\n",
    "wave_sample_rate, wave_audio=wav.read(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ca8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf02c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(wave_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f646e84a",
   "metadata": {},
   "source": [
    "### Extract Features\n",
    "\n",
    "We will be using Mel-Frequency Cepstral Coefficients(MFCC) from the audio samples. The MFCC summarizes the frequency distribution across the window size, so it is possible to analyze both the frequency and time characteristics of the sound. These audio representations will allow us to identify features for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a2a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs=librosa.feature.mfcc(y=librosa_audio_data,sr=librosa_sample_rate,n_mfcc=40)\n",
    "print(mfccs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb0d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f64e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "audio_dataset_path=\"urb\"\n",
    "metadata=pd.read_csv()\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cfe9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    audio,sample_rate=librosa.load(file_name,res_type=\"kaiser_fast\")\n",
    "    mfccs_features=librosa.feature.mfcc(y=audio,sr=sample_rate,n_mfcc=40)\n",
    "    mfccs_scaled_features=np.mean(mfccs_features.T,axis=0)\n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b69b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "extracted_features=[]\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    file_name=os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row['fold'])+'/',str(row['slice_file_name']))\n",
    "    final_class_labels=row['class']\n",
    "    data=features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417dbb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2f6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e751dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42394aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0668b4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bc8ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdecd57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9905aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d82f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff00f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f4dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadb867f",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b93a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81d480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a22cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lables.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce0673",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9061b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential()\n",
    "# model.add(Dense(100,input_shape=(40,)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(200))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(100))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(num_labels))\n",
    "# model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd722332",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    Dense(100,input_shapes=(40,),activation='relu'),\n",
    "    Dropout(0,5),\n",
    "    Dense(200,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_labels,activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5a1948",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba9442",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a095b440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "num_epochs=100\n",
    "num_batch_size=32\n",
    "checkpointer=ModelCheckpoint(filepath='',verbose=1,save_best_only=True)\n",
    "start=datetime.now()\n",
    "model.fit(X_train,y_train,batch_size=batch_size,epochs=num_epochs,validation_data=(X_test,y_test),callbacks=[checkpointer])\n",
    "duration=datetime.now()-start\n",
    "print(\"Training completed in time: \",duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b051c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test, verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4461637",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"\"\n",
    "prediction_feature=features_extractor(filename)\n",
    "prediction_feature=prediction_feature.reshape(1,-1)\n",
    "model.predict_classes(prediction_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721db313",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb3cd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abac962",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7fccda",
   "metadata": {},
   "source": [
    "### Testing Some Test Audio Data\n",
    "\n",
    "Steps\n",
    "* Preprocess the new audio data\n",
    "* predict the classes\n",
    "* Inverse Transform your Predicted Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4550505",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"\"\n",
    "audio, sample_rate=librosa.load(file_name,res_type=\"kaiser_fast\")\n",
    "mfccs_features=librosa.feature.mfcc(y=audio,sr=sample_rate,n_mfcc=40)\n",
    "mfccs_scaled_features=np.mean(mfccs_features.T,axis=0)\n",
    "\n",
    "print(mfccs_scaled_features)\n",
    "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "print(mfccs_scaled_features)\n",
    "print(mfccs_scaled_features.shape)\n",
    "predicted_label=model.predict_classes(mfccs_scaled_features)\n",
    "print(predicted_label)\n",
    "prediction_class=labelencoder.inverse_transform(predicted_label)\n",
    "prediction_class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-processing-ml (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
