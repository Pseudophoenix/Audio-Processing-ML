{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6cd712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2c53ab",
   "metadata": {},
   "source": [
    "### Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007dffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile as wav\n",
    "wave_sample_rate, wave_audio=wav.read(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ca8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf02c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(wave_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f646e84a",
   "metadata": {},
   "source": [
    "### Extract Features\n",
    "\n",
    "We will be using Mel-Frequency Cepstral Coefficients(MFCC) from the audio samples. The MFCC summarizes the frequency distribution across the window size, so it is possible to analyze both the frequency and time characteristics of the sound. These audio representations will allow us to identify features for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a2a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs=librosa.feature.mfcc(y=librosa_audio_data,sr=librosa_sample_rate,n_mfcc=40)\n",
    "print(mfccs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb0d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f64e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "audio_dataset_path=\"urb\"\n",
    "metadata=pd.read_csv()\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cfe9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    audio,sample_rate=librosa.load(file_name,res_type=\"kaiser_fast\")\n",
    "    mfccs_features=librosa.feature.mfcc(y=audio,sr=sample_rate,n_mfcc=40)\n",
    "    mfccs_scaled_features=np.mean(mfccs_features.T,axis=0)\n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b69b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "extracted_features=[]\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    file_name=os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row['fold'])+'/',str(row['slice_file_name']))\n",
    "    final_class_labels=row['class']\n",
    "    data=features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-processing-ml (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
